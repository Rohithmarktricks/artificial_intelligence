{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It allows you to create binaries of your data\n",
    "\n",
    "It simplifies creating data binaries for saving/loading data with TFRecords\n",
    "\n",
    "Key/Value relationship inside dictionary-like object \n",
    "\n",
    "Arranged with datatypes and nested for full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFExample is just an example of serializing dictionaries to byte strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To read data efficiently it can be helpful to serialize your data and store it in a set of files (100-200MB each) that can each be read linearly. This is especially true if the data is being streamed over a network. This can also be useful for caching any data-preprocessing.\n",
    "\n",
    "##### The TFRecord format is a simple format for storing a sequence of binary records.\n",
    "\n",
    "##### Protocol buffers are a cross-platform, cross-language library for efficient serialization of structured data.\n",
    "\n",
    "##### Protocol messages are defined by .proto files, these are often the easiest way to understand a message type.\n",
    "\n",
    "##### The tf.Example message (or protobuf) is a flexible message type that represents a {\"string\": value} mapping. It is designed for use with TensorFlow and is used throughout the higher-level APIs such as TFX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a dataset using tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_observations = 10000\n",
    "\n",
    "feature0=np.random.choice([False, True], n_observations)\n",
    "feature1 = np.random.randint(0, 5, n_observations)\n",
    "strings = np.array([b'a', b'b', b'c', b'd', b'e'])\n",
    "feature2 = strings[feature1]\n",
    "feature3 = np.random.randn(n_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dataset = tf.data.Dataset.from_tensor_slices((feature0, feature1, feature2, feature3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((), (), (), ()), types: (tf.bool, tf.int32, tf.string, tf.float64)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(False, shape=(), dtype=bool)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(b'a', shape=(), dtype=string)\n",
      "tf.Tensor(-0.15304671816324567, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "for f0, f1, f2, f3 in features_dataset.take(1):\n",
    "    print(f0)\n",
    "    print(f1)\n",
    "    print(f2)\n",
    "    print(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the couple of helper functions, used to convert numpy array data types to TFExample data types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_features(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_features(value):\n",
    "    return tf.train.Feature(float_list = tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_features(value):\n",
    "    return tf.train.Feature(int64_list = tf.train.Int64List(value=[value]))\n",
    "\n",
    "def serialize_example(feature0, feature1, feature2, feature3):\n",
    "    feature = {\n",
    "        'feature0':_int64_features(feature0),\n",
    "        'feature1':_int64_features(feature1),\n",
    "        'feature2':_bytes_features(feature2),\n",
    "        'feature3':_float_features(feature3)\n",
    "    }\n",
    "    # Create a Features message using tf.train.Example.\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\nO\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x04\\n\\x11\\n\\x08feature2\\x12\\x05\\n\\x03\\n\\x01c\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04$\\xb9\\xfc='"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the serialize_example function\n",
    "\n",
    "serialized_example = serialize_example(False, 4, b'c', 0.1234)\n",
    "serialized_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "features {\n",
       "  feature {\n",
       "    key: \"feature0\"\n",
       "    value {\n",
       "      int64_list {\n",
       "        value: 0\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"feature1\"\n",
       "    value {\n",
       "      int64_list {\n",
       "        value: 4\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"feature2\"\n",
       "    value {\n",
       "      bytes_list {\n",
       "        value: \"c\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"feature3\"\n",
       "    value {\n",
       "      float_list {\n",
       "        value: 0.1234000027179718\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exampled_returned = tf.train.Example.FromString(serialized_example)\n",
    "exampled_returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFRecords\n",
    "\n",
    "Simple format for storing a sequence of binary records. Efficiently reads data linearly from disk. This format is especially beneficial if streamed over network\n",
    "\n",
    "TFExample can convert into binary records. TFRecord will convert that binary into some processor where we can load data quicker from a disk\n",
    "\n",
    "\n",
    "Caveat: TFRecord adds complexity. Only use if bottleneck in training is loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, Saving and loading data from tf.example using TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_serialize_example(f0, f1, f2, f3):\n",
    "    tf_string=tf.py_function(\n",
    "    serialize_example,\n",
    "    (f0, f1, f2, f3),\n",
    "    tf.string)\n",
    "    return tf.reshape(tf_string, ())# The result is a scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized_dataset = features_dataset.map(tf_serialize_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serialized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    for features in features_dataset:\n",
    "        yield serialize_example(*features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized_dataset = tf.data.Dataset.from_generator(generator, output_types=tf.string, output_shapes=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serialized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### filename = 'tf_data_pipelines.tfrecord'\n",
    "###### writer = tf.data.experimental.TFRecordWriter(filename)\n",
    "###### writer.write(serialized_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filenames=[filname]\n",
    "\n",
    "raw_dataset=tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
